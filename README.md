# DPO_practice
## easy_DPO
- A submodule which is about using DPO easily.
- Forked from https://github.com/DopeorNope-Lee/Easy_DPO
- Able to check a model DPO-trained 'Bllossom/llama-3.2-Korean-Bllossom-3B', which was trained using DPO while gradually increasing the proportion of Korean.
- Used datasets are [here](https://huggingface.co/datasets/ibivibiv/cleaned_orca_math_dpo_pairs) for english, and [here](https://huggingface.co/datasets/kuotient/orca-math-korean-dpo-pairs?row=0) for korean.

## llama3B_DPO
- To develop the Korean ability of Llama-3.2B, which already has Korean capability, using DPO.
- Still being modified..